{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f327809b6a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/groot/Websites/note/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows =10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "df=df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "df[\"median_house_value\"] /= 1000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Feature and Feature Column aka predictor\n",
    "\n",
    "1. ** feature_data **\n",
    "* ** feature_column aka description ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data   = df[[\"total_rooms\"]]\n",
    "feature_column = [tf.feature_column.numeric_column(\"total_rooms\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Linear regression configs here\n",
    "\n",
    "1. optimizer : Type\n",
    "* optimizer : clip_gradient\n",
    "\n",
    "2. linear regressor: tf.estimator( feature_column , optimizer from 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.train.GradientDescentOptimizer(learning_rate=0000001)\n",
    "\n",
    "opt=tf.contrib.estimator.clip_gradients_by_norm(opt, 5.0)\n",
    "\n",
    "linear_regressor=tf.estimator.LinearRegressor(\n",
    "    \n",
    "    feature_columns= feature_column, \n",
    "    optimizer=opt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Make Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "\n",
    "    features={key : np.array(value) for key, value in dict(features).items() }\n",
    "\n",
    "# dataset opertions \n",
    "    \n",
    "    ds=Dataset.from_tensor_slices( (features, targets)  )\n",
    "    ds=ds.batch(batch_size).repeat(num_epochs)\n",
    "#     Shuffle datset\n",
    "\n",
    "    if shuffle:\n",
    "        ds=ds.shuffle(buffer_size=10000)\n",
    "        \n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ =linear_regressor.train(\n",
    "input_fn = lambda: my_input_fn(feature_data, target),\n",
    "    steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input_fn = lambda: my_input_fn(feature_data, target, num_epochs =1, shuffle=False)\n",
    "\n",
    "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "\n",
    "predictions =np.array(  \n",
    "                        [item[\"predictions\"][0] for item in predictions]\n",
    "                    )\n",
    "\n",
    "mse= metrics.mean_squared_error(predictions, target)\n",
    "rmse= math.sqrt(mse)\n",
    "\n",
    "print(\"MSE : %0.3f\" %mse )\n",
    "print(\"RMSE: %0.3f\" %rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare MSE and RMSE with range of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_v= df[\"median_house_value\"].min()\n",
    "max_v= df[\"median_house_value\"].max()\n",
    "range_v= max_v - min_v\n",
    "\n",
    "print(\"MIN  : %0.3f\" %min_v )\n",
    "print(\"MAX  : %0.3f\" %max_v)\n",
    "print(\"RANGE: %0.3f\" %range_v )\n",
    "print(\"RMSE : %0.3f\" %rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_df=pd.DataFrame()\n",
    "cal_df[\"predictions\"]=pd.Series(predictions)\n",
    "cal_df[\"target\"]=pd.Series(target)\n",
    "cal_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=df.sample(n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Ploting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = sample[\"total_rooms\"].min()\n",
    "x_1 = sample[\"total_rooms\"].min()\n",
    "\n",
    "weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
    "bias   = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
    "\n",
    "y_0 = weight * x_0 + bias\n",
    "y_1 = weight * x_1 + bias\n",
    "\n",
    "plt.plot([x_0, x_1], [y_0, y_1], c='r')\n",
    "\n",
    "plt.ylabel(\"median_house_value\")\n",
    "plt.xlabel(\"total_rooms\")\n",
    "\n",
    "plt.scatter(sample[\"total_rooms\"], sample[\"median_house_value\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Library for our process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(learning_rate, steps, batch_size, input_feature=\"total_rooms\"):\n",
    "    \n",
    "    periods=10\n",
    "    steps_per_period= steps / periods\n",
    "    \n",
    "    my_feature=input_feature\n",
    "    my_feature_data = df[[my_feature]]\n",
    "    my_label= \"median_house_value\"\n",
    "    targets= df[my_label]\n",
    "    \n",
    "    # CReate feature columns     \n",
    "    feature_columns= [tf.feature_column.numeric_column(my_feature)]\n",
    "    \n",
    "    # CReate input functions\n",
    "    training_input_fn = lambda: my_input_fn(\n",
    "                                            my_feature_data,\n",
    "                                            targets,\n",
    "                                            batch_size=batch_size)\n",
    "    predictions_input_fn = lambda:my_input_fn(my_feature_data, \n",
    "                                              targets, \n",
    "                                              num_epochs=1, \n",
    "                                              shuffle= False)  \n",
    "    \n",
    "    # Create Linear Regressor\n",
    "    opt=tf.train.GradientDescentOptimizer(learning_rate=0.00001)\n",
    "    opt=tf.contrib.estimator.clip_gradients_by_norm(opt, 5.0)\n",
    "\n",
    "    linear_regressor=tf.estimator.LinearRegressor(\n",
    "        feature_columns =feature_columns,\n",
    "        optimizer=opt\n",
    "        )\n",
    "    \n",
    "    # Set up plotting      \n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Learned Line By Period\")\n",
    "    plt.ylabel(my_label)\n",
    "    plt.xlabel(my_feature)\n",
    "    sample=df.sample(n=300)\n",
    "    plt.scatter(sample[my_feature], sample[my_label])\n",
    "    colors = [ cm.coolwarm(x) \n",
    "              for x in np.linspace(-1, 1, periods)\n",
    "             ]\n",
    "\n",
    "    # Training model in loop\n",
    "    print \"TRainging model....\"\n",
    "    print \"RMSE on training data...\"\n",
    "    \n",
    "    rmses=[]\n",
    "    \n",
    "    for period in range (0, periods):\n",
    "        linear_regressor.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        \n",
    "        predictions =linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "        predictions =np.array([\n",
    "                                item[\"predictions\"][0] \n",
    "                                for item in predictions\n",
    "                                ])\n",
    "        # Compute Loss      \n",
    "        rmse = math.sqrt(\n",
    "            metrics.mean_squared_error(predictions, targets)\n",
    "            )\n",
    "        # Print current loss\n",
    "        print \" period %02d; %0.2f\" % (period, rmse)\n",
    "    \n",
    "        # Add to our list\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "        # Starting Plots         \n",
    "        y_extents =np.array([0, sample[my_label].max()])\n",
    "        \n",
    "        weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
    "        bias   = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
    "        \n",
    "        x_extents = (y_extents - bias) / weight\n",
    "        x_extents = np.maximum(np.minimum(x_extents,\n",
    "                                      sample[my_feature].max()),\n",
    "                           sample[my_feature].min())\n",
    "        y_extents = weight * x_extents + bias\n",
    "        plt.plot(x_extents, y_extents, color=colors[period]) \n",
    "    \n",
    "    print \"Modeling done\"\n",
    "    \n",
    "    # Start Plotting\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.ylabel(\"RMSEs\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"RMSEs vs Periods\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot(rmses)\n",
    "    \n",
    "\n",
    "    # Output Table calibrated \n",
    "    calibration_data = pd.DataFrame()\n",
    "    calibration_data[\"predictions \"]=pd.Series(predictions)\n",
    "    calibration_data[\"targets\"] =pd.Series(targets)\n",
    "    display.display(calibration_data.describe())\n",
    "    \n",
    "    print \"Final RMSE : %0.2f\" % rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    learning_rate=0.000005,\n",
    "    steps=200,\n",
    "    batch_size =15\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
